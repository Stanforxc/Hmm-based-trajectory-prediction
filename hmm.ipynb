{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from __future__  import print_function\n",
    "import pandas as pd\n",
    "from HiddenMarkovModel import HiddenMarkovModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 定义预处理函数，读入数据预处理，包括取相关列，计算RSSI以及去除nan值\n",
    "def pre_processing(filename):\n",
    "    file_2g = pd.read_csv(filename).loc[:,['MRTime','Grid_center_x','Grid_center_y','RNCID_1', 'CellID_1','EcNo_1', 'RSCP_1', 'RNCID_2', 'CellID_2','EcNo_2', 'RSCP_2','RNCID_3', 'CellID_3','EcNo_3', 'RSCP_3', 'RNCID_4', 'CellID_4','EcNo_4', 'RSCP_4', 'RNCID_5', 'CellID_5','EcNo_5', 'RSCP_5', 'RNCID_6', 'CellID_6','EcNo_6', 'RSCP_6','Grid_ID']]\n",
    "    gong_can = pd.read_csv(\"final_2g_gongcan.csv\", encoding='gbk').loc[:,['CGI', 'LAC', 'CI', u'经度', u'纬度']]\n",
    "    \n",
    "    for i in range(6):\n",
    "        RNCID = \"RNCID_\" + str(i+1)\n",
    "        CellID = \"CellID_\" + str(i+1)\n",
    "        station = pd.merge(file_2g, gong_can, left_on=[RNCID, CellID], right_on=['LAC','CI'], how='inner')[['CGI']]\n",
    "        file_2g[[str(i+1)+'station']] = station\n",
    "        file_2g['RSSI'+str(i+1)] = file_2g['EcNo_' + str(i+1)] - file_2g['RSCP_' + str(i+1)]\n",
    "\n",
    "    merge_data = file_2g\n",
    "    \n",
    "    merge_data['MRTime'] = merge_data['MRTime'].str.split()\n",
    "    timeCol = pd.Series(map(lambda x:x[1],merge_data['MRTime']),index=merge_data.index)\n",
    "    timeCol = pd.to_datetime(timeCol,format=\"%H:%M:%S.%f\")\n",
    "    merge_data['MRTime'] = timeCol\n",
    "    \n",
    "    merge_data = merge_data.sort_values(by=['MRTime'])\n",
    "    \n",
    "    for i in range(1,7):\n",
    "        del merge_data['EcNo_' + str(i)],merge_data['RSCP_' + str(i)]\n",
    "        \n",
    "    for i in range(1,7):\n",
    "        del merge_data['RNCID_' + str(i)],merge_data['CellID_' + str(i)]\n",
    "        \n",
    "    return merge_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#读取数据\n",
    "train_data = pd.read_csv('train_data_after_process.csv',index_col=\"Unnamed: 0\").drop(78066)\n",
    "test_data = pre_processing('final_2g_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#去某条轨迹，如果这里去了第三条轨迹做示例\n",
    "trace = pd.read_csv('newtrace.csv',index_col=\"Unnamed: 0\")\n",
    "del trace[\"Unnamed: 0.1\"]\n",
    "trace['MRTime'] = pd.to_datetime(trace['MRTime'],format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "traj_1 = trace[trace['path_index'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "station_compared_traj = []\n",
    "rssi_code_traj = []\n",
    "for i in range(1, 6 + 1):\n",
    "    station_compared_traj.append('Station_' + str(i))\n",
    "    rssi_code_traj.append('RSSI_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 计算emission score的中间步骤\n",
    "observables = []\n",
    "new_pattern = train_data[station_compared_traj]\n",
    "big_mat = train_data[rssi_code_traj]\n",
    "for row in traj_1.index:\n",
    "    #取出test数据集中的某一条记录\n",
    "    fnew = traj_1.loc[row]\n",
    "    #取出该记录能在共参表里匹配到的基站\n",
    "    ls = fnew[station_compared_traj].dropna().tolist()\n",
    "    #取出改记录的RSSI向量，如果没有信号则置为零\n",
    "    rssi = np.array(fnew[rssi_code_traj].tolist())\n",
    "    #取出匹配的中间0/1矩阵，做加速用，算是小trick\n",
    "    after_process = new_pattern[new_pattern.isin(ls)].dropna(axis=0,how='all').fillna(0) != 0\n",
    "    #得到train数据中匹配的RSSI矩阵\n",
    "    rssi_matrix = big_mat.loc[after_process.index]\n",
    "    #算出匹配后的rssi矩阵\n",
    "    fnewMatrix = after_process*rssi\n",
    "    patternMatrix = after_process*rssi_matrix.values\n",
    "    \n",
    "    #定义一些中间量\n",
    "    traj_sum = 'traj_sum' + str(row)\n",
    "    M = 'M' + str(row)\n",
    "    observable = 'obeservable_' + str(row)\n",
    "    #定义观察链\n",
    "    observables.append(observable)\n",
    "    #计算欧式距离\n",
    "    train_data[traj_sum] = np.sqrt(((fnewMatrix - patternMatrix)**2).sum(axis=1))\n",
    "    #动态得到dRmax\n",
    "    max_rssi = train_data[traj_sum].max()\n",
    "    #得到匹配基站数M\n",
    "    train_data[M] = after_process.sum(axis=1)\n",
    "    #初始化\n",
    "    train_data[observable] = 0\n",
    "    middleware = train_data[train_data[M] > 0]\n",
    "    #使用M×3+（dRmax - dR(F1,F2)）\n",
    "    train_data.loc[middleware.index,observable] = middleware[M] * 3 + (max_rssi - middleware[traj_sum] / middleware[M])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# emision矩阵\n",
    "groups = train_data.groupby(['Grid_ID'])\n",
    "emission = groups[observables].agg(np.max).T\n",
    "emission_matrix = ((emission - emission.min()) / (emission.max() - emission.min()))\n",
    "                    .dropna(axis = 1) #min-max normalizd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#匹配基站坐标,对后面做匹配用\n",
    "Grid_ID = train_data[['Grid_ID','Grid_center_y','Grid_center_x']].drop_duplicates().dropna()\n",
    "Grid_ID.index = Grid_ID['Grid_ID']\n",
    "del Grid_ID['Grid_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trans矩阵\n",
    "manhattan = Grid_ID.loc[emission_matrix.columns].values\n",
    "trans = manhattan_distances(manhattan,manhattan)\n",
    "\n",
    "#曼哈顿距离计算，haversine作为垂直和水平距离\n",
    "manhattan_ls = []\n",
    "for i in manhattan:\n",
    "    tmp_ls = []\n",
    "    for j in manhattan:\n",
    "        vertical = haversine(i[1],i[0],i[1],j[0])\n",
    "        horizontal = haversine(i[1],i[0],j[1],i[0])\n",
    "        tmp_ls.append((np.abs(vertical) + np.abs(horizontal))/30.0)\n",
    "    manhattan_ls.append(tmp_ls)\n",
    "trans = np.array(manhattan_ls)\n",
    "\n",
    "#将对角线置为1\n",
    "np.fill_diagonal(trans,1)\n",
    "trans_matrix = pd.DataFrame(trans,index=emission_matrix.columns,columns=emission_matrix.columns)\n",
    "trans_matrix_reverse = 1/trans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#做成输入的标准矩阵\n",
    "emi_mat = emission_matrix.as_matrix()\n",
    "trans_mat = trans_matrix_reverse.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#初始概率，只展示效果较好的初始概率，即平均\n",
    "allNumber = len(trans_mat)\n",
    "p0 = [1.0/allNumber for i in range(allNumber)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#定义模型\n",
    "model =  HiddenMarkovModel(trans_mat, emi_mat, p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From HiddenMarkovModel.py:123 in run_viterbi.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From HiddenMarkovModel.py:128 in run_viterbi.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "states_seq, state_prob = model.run_viterbi([i for i in range(len(emission_matrix))],summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#回溯匹配\n",
    "grid = emission_matrix.columns[states_seq]\n",
    "predict = Grid_ID.loc[grid]#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "original_ls = traj_1[['Grid_center_y','Grid_center_x']].values.tolist()\n",
    "predict_ls = predict.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#误差计算，使用haversine距离\n",
    "error_ls = []\n",
    "for (x,y) in zip(original,predict):\n",
    "    error_ls.append(haversine(x[1],x[0],y[1],y[0]))\n",
    "    \n",
    "#平均误差\n",
    "error_mean = np.mean(ls)\n",
    "#做图\n",
    "plt.plot(error_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict.loc['Grid_ID'] = grid\n",
    "predict.to_csv(\"hmm2Input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt  \n",
    "      \n",
    "def haversine(lon1, lat1, lon2, lat2): # 经度1，纬度1，经度2，纬度2 （十进制度数）  \n",
    "    \"\"\" \n",
    "    Calculate the great circle distance between two points  \n",
    "    on the earth (specified in decimal degrees) \n",
    "    \"\"\"  \n",
    "    # 将十进制度数转化为弧度  \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])  \n",
    "      \n",
    "    # haversine公式  \n",
    "    dlon = lon2 - lon1   \n",
    "    dlat = lat2 - lat1   \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2  \n",
    "    c = 2 * asin(sqrt(a))   \n",
    "    r = 6371 # 地球平均半径，单位为公里  \n",
    "    return c * r * 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From HiddenMarkovModel.py:123 in run_viterbi.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From HiddenMarkovModel.py:128 in run_viterbi.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# HiddenMarkov.py Simple Example\n",
    "\n",
    "p0 = np.array([0.6,0.4])\n",
    "emi = np.array([[0.5,0.1],\n",
    "               [0.4,0.3],\n",
    "               [0.1,0.6]])\n",
    "trans = np.array([[0.7,0.3],\n",
    "                 [0.4,0.6]])\n",
    "states = {0:'Healthy',1:'Fever'}\n",
    "\n",
    "obs = {0:'normal',1:'cold',2:'dizzy'}\n",
    "\n",
    "obs_seq = np.array([0,0,1,2,2])\n",
    "\n",
    "df_p0 = pd.DataFrame(p0,index=['Healthy','Fever'],columns=['Prob'])\n",
    "df_emi = pd.DataFrame(emi,index=['Normal','Cold','Dizzy'],columns=['Healthy','Fever'])\n",
    "df_trans = pd.DataFrame(trans,index=['fromHealthy','fromFever'],columns=['toHealthy','toFever'])\n",
    "\n",
    "\n",
    "\n",
    "model =  HiddenMarkovModel(trans, emi, p0)\n",
    "states_seq, state_prob = model.run_viterbi(obs_seq, summary=True)\n",
    "\n",
    "print(states_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author : 夏陈 ，洪嘉勇\n",
    "# 如有疑问，欢迎发邮件 stanforxc@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
